{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Lineal en Python - Paso a Paso\n",
    "\n",
    "En este notebook aprenderemos a realizar **Regresión Lineal** usando Python y la librería **scikit-learn**.\n",
    "\n",
    "## Contenido\n",
    "1. ¿Qué es la Regresión Lineal?\n",
    "2. Importar librerías necesarias\n",
    "3. Generar datos de ejemplo\n",
    "4. Exploración y visualización de datos\n",
    "5. División en entrenamiento y prueba\n",
    "6. Entrenar el modelo de Regresión Lineal\n",
    "7. Evaluar el modelo\n",
    "8. Visualizar la recta de mejor ajuste\n",
    "9. Realizar predicciones con nuevos datos\n",
    "10. Interpretación de los Betas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ¿Qué es la Regresión Lineal?\n",
    "\n",
    "La **regresión lineal** es un método estadístico que busca modelar la relación entre una **variable dependiente** (Y) y una o varias **variables independientes** (X):\n",
    "\n",
    "- **Regresión Lineal Simple**: Cuando solo hay una variable explicativa (X).\n",
    "- **Regresión Lineal Múltiple**: Cuando hay dos o más variables explicativas (X1, X2, ...).\n",
    "\n",
    "La forma **simple** de la regresión lineal asume que:\n",
    "\n",
    "\\[Y = \\beta_0 + \\beta_1 X + \\varepsilon\\]\n",
    "\n",
    "donde:\n",
    "- \\(\\beta_0\\) es la intersección (intercept) con el eje Y.\n",
    "- \\(\\beta_1\\) es la pendiente (slope).\n",
    "- \\(\\varepsilon\\) es un término de error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {}
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generar datos de ejemplo\n",
    "\n",
    "En este ejemplo crearemos datos sintéticos para ilustrar la **Regresión Lineal Simple**:\n",
    "- Asumiremos que la verdadera relación entre X e Y es: \\(Y = 2 + 3X + \\text{ruido}\\)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {}
   },
   "source": [
    "# Fijamos una semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generamos 100 valores de X en el rango [0, 10]\n",
    "X = 10 * np.random.rand(100, 1)\n",
    "\n",
    "# Generamos la relación verdadera + ruido\n",
    "# Y = 2 + 3X + ruido\n",
    "y = 2 + 3 * X[:, 0] + np.random.randn(100)\n",
    "\n",
    "# Convertimos en un DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'X': X[:, 0],\n",
    "    'Y': y\n",
    "})\n",
    "\n",
    "df.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploración y visualización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {}
   },
   "source": [
    "# Resumen estadístico\n",
    "df.describe()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {}
   },
   "source": [
    "# Gráfico de dispersión para ver la relación entre X y Y\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='X', y='Y', data=df, color='blue')\n",
    "plt.title(\"Relación entre X y Y\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. División en entrenamiento y prueba\n",
    "\n",
    "Dividimos el conjunto de datos en **entrenamiento** y **prueba** para evaluar la capacidad de generalización del modelo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {}
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['X']],  # Asegurar 2D para sklearn\n",
    "    df['Y'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"Prueba: {X_test.shape[0]} muestras\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entrenar el modelo de Regresión Lineal\n",
    "\n",
    "Usamos la clase `LinearRegression` de **scikit-learn** para crear y ajustar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {}
   },
   "source": [
    "# Crear instancia del modelo\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Extraer los coeficientes\n",
    "intercept = model.intercept_\n",
    "coef = model.coef_[0]\n",
    "\n",
    "print(f\"Intercept (beta_0): {intercept:.2f}\")\n",
    "print(f\"Coeficiente (beta_1): {coef:.2f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluar el modelo\n",
    "\n",
    "Calculamos dos métricas fundamentales:\n",
    "- **MSE (Mean Squared Error)** o Error Cuadrático Medio\n",
    "- **R^2 (Coeficiente de Determinación)**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {}
   },
   "source": [
    "# Predicciones en entrenamiento y prueba\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# MSE y R^2 en entrenamiento\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "# MSE y R^2 en prueba\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Conjunto de Entrenamiento:\")\n",
    "print(f\"MSE: {mse_train:.2f}\")\n",
    "print(f\"R^2: {r2_train:.2f}\")\n",
    "print(\"\\nConjunto de Prueba:\")\n",
    "print(f\"MSE: {mse_test:.2f}\")\n",
    "print(f\"R^2: {r2_test:.2f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizar la recta de mejor ajuste\n",
    "\n",
    "Graficamos la línea de regresión superpuesta a los datos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {}
   },
   "source": [
    "# Creamos un rango de valores de X para trazar la línea del modelo\n",
    "X_line = np.linspace(df['X'].min(), df['X'].max(), 100).reshape(-1, 1)\n",
    "y_line = model.predict(X_line)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X_train['X'], y=y_train, color='blue', label='Entrenamiento')\n",
    "sns.scatterplot(x=X_test['X'], y=y_test, color='red', label='Prueba')\n",
    "plt.plot(X_line, y_line, color='black', linewidth=2, label='Modelo')\n",
    "plt.title(\"Regresión Lineal - Recta de Mejor Ajuste\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Realizar predicciones con nuevos datos\n",
    "\n",
    "Supongamos que queremos estimar el valor de `Y` para valores de `X` que no están en nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {}
   },
   "source": [
    "# Nuevos valores de X (por ejemplo, 2, 5, 7.5, 10)\n",
    "X_new = np.array([2.0, 5.0, 7.5, 10.0]).reshape(-1, 1)\n",
    "\n",
    "# Predicciones del modelo\n",
    "y_new_pred = model.predict(X_new)\n",
    "\n",
    "print(\"Nuevos valores de X:\", X_new.flatten())\n",
    "print(\"Predicciones de Y:\", y_new_pred.round(2))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interpretación de los Betas\n",
    "\n",
    "En la regresión lineal simple:\n",
    "- \\(\\beta_0\\) (Intercept) es el valor promedio de Y cuando \\(X = 0\\).\n",
    "- \\(\\beta_1\\) (Coeficiente) representa cómo cambia Y en promedio por cada **unidad** que aumenta X.\n",
    "\n",
    "Por ejemplo, si \\(\\beta_1 = 3.05\\), significa que por **cada aumento de 1 en X**, Y aumenta en aproximadamente **3.05 unidades** (manteniendo constantes las demás variables, aunque en este caso solo hay una variable).\n",
    "\n",
    "El valor que obtuvimos como intercept (`beta_0`) nos indica el punto en el que la recta de regresión cruza el eje Y cuando X=0.\n",
    "\n",
    "---\n",
    "### Conclusión\n",
    "En este notebook:\n",
    "- Generamos un dataset sintético.\n",
    "- Entrenamos un modelo de Regresión Lineal Simple.\n",
    "- Evaluamos el modelo con MSE y R^2.\n",
    "- Visualizamos la recta ajustada.\n",
    "- Hicimos predicciones con datos nuevos.\n",
    "- Interpretamos brevemente los coeficientes (betas).\n",
    "\n",
    "¡Así de sencillo es empezar con la regresión lineal en Python!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
